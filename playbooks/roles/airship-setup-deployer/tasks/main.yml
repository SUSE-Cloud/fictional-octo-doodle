---
- name: Load common variables
  include_vars: "{{ item }}"
  loop:
    - "{{ playbook_dir }}/roles/common-deployer/defaults/main.yml"
  tags:
    - always

- name: Add zypper extra repositories
  become: yes
  zypper_repository:
    name: "{{ item['key'] }}"
    repo: "{{ item['value'] }}"
    autorefresh: True
    auto_import_keys: yes
    state: present
  loop: "{{ zypper_extra_repos | dict2items }}"

- name: Install system packages
  become: yes
  package:
    name: "{{ suse_deployer_packages }}"
    state: present
  register: install_packages
  until: install_packages is success
  retries: 5
  delay: 2
  tags:
    - install

- name: Install OpenStack client packages
  become: yes
  package:
    name: "{{ suse_openstackclient_packages }}"
    state: present
  retries: 5
  delay: 2
  tags:
    - install

- name: Enable docker systemd service
  become: yes
  systemd:
    name: docker
    state: started
    enabled: yes
  tags:
    - install

- name: Add the user to the group 'docker'
  become: yes
  user:
    name: "{{ lookup('env','USER') }}"
    groups: docker
    append: yes

- name: Ensure kubectl is properly configured
  include_role:
    name: common-deployer
    tasks_from: kubectl-setup
  tags:
    - install

- name: Ensure helm and tiller are up to date
  include_role:
    name: common-deployer
    tasks_from: helm-install
  tags:
    - install

- name: Ensure helm runs on localhost
  include_role:
    name: common-deployer
    tasks_from: helm-run
  tags:
    - run

- name: Install local path provisioner
  include_role:
    name: common-deployer
    tasks_from: local-provisioner
  tags:
    - install

# Need to use specific marker to avoid overwriting via other step
- name: Ensure VIP is present in /etc/hosts for the services to deploy
  become: yes
  blockinfile:
    path: /etc/hosts
    marker: "# {mark} ANSIBLE MANAGED BLOCK for VIP entries"
    block: |
      # UCP service public end points
      {{ ext_vip }} keystone.ucp.svc.cluster.local keystone-api.ucp.svc.cluster.local
      {{ ext_vip }} barbican.ucp.svc.cluster.local barbican-api.ucp.svc.cluster.local
      {{ ext_vip }} shipyard.ucp.svc.cluster.local
      # Openstack admin service and internal endpoints
      {{ ext_vip }} identity-api.openstack.svc.cluster.local
      {{ ext_vip }} image-api.openstack.svc.cluster.local
      {{ ext_vip }} volume-api.openstack.svc.cluster.local
      {{ ext_vip }} compute-api.openstack.svc.cluster.local
      {{ ext_vip }} network-api.openstack.svc.cluster.local
      {{ ext_vip }} dashboard-api.openstack.svc.cluster.local
      {{ ext_vip }} orchestration-api.openstack.svc.cluster.local
      # Openstack service public endpoints
      {{ ext_vip }} identity.openstack.svc.cluster.local
      {{ ext_vip }} image.openstack.svc.cluster.local
      {{ ext_vip }} volume.openstack.svc.cluster.local
      {{ ext_vip }} compute.openstack.svc.cluster.local
      {{ ext_vip }} network.openstack.svc.cluster.local
      {{ ext_vip }} dashboard.openstack.svc.cluster.local
      {{ ext_vip }} nova-novncproxy.openstack.svc.cluster.local
      {{ ext_vip }} orchestration.openstack.svc.cluster.local

- name: Creates /etc/openstack directory
  become: yes
  file:
    path: "{{ item }}"
    state: directory
    #   owner: "{{ ansible_user }}"
  with_items:
    - /etc/openstack

- name: Copy clouds.yml
  become: yes
  template:
    src: clouds.yml.j2
    dest: /etc/openstack/clouds.yaml

- name: Save Shipyard env variables to ~/.airshiprc
  blockinfile:
    path: "{{ ansible_user_dir }}/.airshiprc"
    create: yes
    mode: "0600"
    block: |
      export SHIPYARD_IMAGE="{{ suse_airship_registry_location }}/airshipit/shipyard:{{ suse_airship_components_image_tag['shipyard'] }}"
      export OS_SHIPYARD_PASSWORD="{{ lookup('password', secrets_location + '/ucp_shipyard_keystone_password ' + password_opts) }}"
